#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
STATISTICAL ANALYSIS HELPERS - FUN√á√ïES AUXILIARES
==================================================
M√≥dulo contendo fun√ß√µes auxiliares para reduzir a complexidade cognitiva
da fun√ß√£o show_statistical_analysis_page().
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from scipy import stats
from scipy.stats import skew, kurtosis
from plotly.subplots import make_subplots
from constants import PETR4_SYMBOL
import statsmodels.api as sm
# Importar fun√ß√µes de interpreta√ß√£o de risco
try:
    from risk_utils import _display_risk_interpretation, _calculate_risk_score, _get_risk_category
except ImportError:
    # Fun√ß√µes de fallback caso o m√≥dulo risk_utils n√£o exista
    def _display_risk_interpretation(risk_metrics):
        """Vers√£o simplificada para exibir interpreta√ß√£o de risco"""
        st.subheader("üí° Interpreta√ß√£o dos Resultados de Risco")
        st.write("Para interpreta√ß√£o completa dos resultados, certifique-se que o m√≥dulo risk_utils est√° dispon√≠vel.")
        
        # Obter valores das m√©tricas principais
        var_95 = risk_metrics.get('var_cvar', {}).get('var_95', 0)
        cvar_95 = risk_metrics.get('var_cvar', {}).get('cvar_95', 0)
        
        st.info(f"""
        ** M√©tricas Principais:**
        - VaR 95%: {var_95:.2%} (em 95% dos casos, a perda n√£o ser√° maior)
        - CVaR 95%: {cvar_95:.2%} (perda m√©dia nos 5% piores casos)
        """)
        
    def _calculate_risk_score(var_95, cvar_95, max_dd, vol_anual):
        """Vers√£o simplificada para c√°lculo de score de risco"""
        return (abs(var_95) * 30 + abs(cvar_95) * 40 + abs(max_dd) * 15 + vol_anual * 15) / 10
    
    def _get_risk_category(risk_score):
        """Vers√£o simplificada para categoriza√ß√£o de risco"""
        if risk_score <= 1.5:
            level = "BAIXO"
        elif risk_score <= 3.0:
            level = "MODERADO"
        else:
            level = "ALTO"


def validate_data_for_operations(data, operation_name="estat√≠stica", min_samples=30, check_columns=None):
    """
    Fun√ß√£o de valida√ß√£o abrangente para verificar dados antes de opera√ß√µes estat√≠sticas.
    
    Par√¢metros:
    -----------
    data : DataFrame
        DataFrame a ser validado
    operation_name : str, default="estat√≠stica"
        Nome da opera√ß√£o para mensagens de erro
    min_samples : int, default=30
        N√∫mero m√≠nimo de amostras necess√°rias
    check_columns : list, default=None
        Lista de colunas espec√≠ficas a serem verificadas
        
    Retorno:
    --------
    tuple
        (is_valid, message) - boolean indicando se os dados s√£o v√°lidos e mensagem descritiva
    """
    # Verifica√ß√µes b√°sicas
    if data is None:
        return False, f"‚ùå Dados n√£o fornecidos para opera√ß√£o {operation_name}"
    
    if not isinstance(data, pd.DataFrame):
        return False, f"‚ùå Tipo de dados inv√°lido para {operation_name} (esperado DataFrame)"
    
    if data.empty:
        return False, f"‚ùå DataFrame vazio para opera√ß√£o {operation_name}"
    
    # Verificar tamanho dos dados
    if len(data) < min_samples:
        return False, f"‚ö†Ô∏è Dados insuficientes para {operation_name} ({len(data)} < {min_samples} m√≠nimo recomendado)"
    
    # Se colunas espec√≠ficas foram especificadas
    if check_columns:
        # Verificar exist√™ncia das colunas
        missing_columns = [col for col in check_columns if col not in data.columns]
        if missing_columns:
            return False, f"‚ùå Colunas necess√°rias n√£o encontradas: {', '.join(missing_columns)}"
        
        # Verificar valores ausentes nas colunas espec√≠ficas
        na_counts = data[check_columns].isna().sum()
        if na_counts.sum() > 0:
            na_info = ", ".join([f"{col}: {count}" for col, count in na_counts.items() if count > 0])
            if na_counts.sum() > len(data) * 0.1:  # Mais de 10% dos dados s√£o NaN
                return False, f"‚ùå Muitos valores ausentes: {na_info}"
            else:
                return True, f"‚ö†Ô∏è Alguns valores ausentes: {na_info} (os c√°lculos podem ser impactados)"
        
        # Verificar valores constantes (vari√¢ncia zero)
        zero_variance = []
        for col in check_columns:
            if data[col].std() < 1e-8:  # Praticamente constante
                zero_variance.append(col)
        
        if zero_variance:
            return False, f"‚ö†Ô∏è Colunas com varia√ß√£o quase zero: {', '.join(zero_variance)}"
    
    # Verificar valores ausentes em geral
    total_na = data.isna().sum().sum()
    if total_na > 0:
        na_percent = total_na / (len(data) * len(data.columns)) * 100
        if na_percent > 10:  # Mais de 10% dos dados s√£o NaN
            return False, f"‚ö†Ô∏è Alto percentual de valores ausentes: {na_percent:.1f}% do total"
        else:
            return True, f"‚ÑπÔ∏è {total_na} valores ausentes ({na_percent:.1f}% do total) - os c√°lculos podem ser impactados"
    
    return True, "‚úÖ Dados v√°lidos para opera√ß√£o"


def plot_scatter_chart(data1, data2, name1, name2, add_regression=True):
    """
    Plota um gr√°fico de dispers√£o (scatter) entre duas s√©ries de dados.
    
    Par√¢metros:
    -----------
    data1 : array ou Series
        Primeira s√©rie de dados
    data2 : array ou Series
        Segunda s√©rie de dados
    name1 : str
        Nome da primeira s√©rie (eixo x)
    name2 : str
        Nome da segunda s√©rie (eixo y)
    add_regression : bool, default=True
        Se True, adiciona uma linha de regress√£o
        
    Retorno:
    --------
    None
    """
    try:
        # Verificar se h√° dados suficientes
        if isinstance(data1, (pd.Series, np.ndarray)) and len(data1) == 0:
            st.warning(f"N√£o h√° dados dispon√≠veis para {name1}")
            return
            
        if isinstance(data2, (pd.Series, np.ndarray)) and len(data2) == 0:
            st.warning(f"N√£o h√° dados dispon√≠veis para {name2}")
            return
            
        # Criar DataFrame para plotly
        scatter_df = pd.DataFrame({
            name1: data1,
            name2: data2
        }).dropna()
        
        # Verificar se h√° dados ap√≥s remo√ß√£o de valores NaN
        if scatter_df.empty or len(scatter_df) < 3:
            st.warning(f"Dados insuficientes para criar gr√°fico de dispers√£o entre {name1} e {name2}")
            return
            
        # Criar gr√°fico de dispers√£o
        fig = px.scatter(
            scatter_df, x=name1, y=name2, 
            title=f"Gr√°fico de Dispers√£o: {name1} vs {name2}",
            trendline="ols" if add_regression and len(scatter_df) >= 3 else None
        )
        
        st.plotly_chart(fig, use_container_width=True)
    except Exception as e:
        st.error(f"Erro ao criar gr√°fico de dispers√£o: {str(e)}")
        st.info("Verifique se os dados s√£o v√°lidos e t√™m formato compat√≠vel.")


def plot_histogram_comparison(data1, data2, name1, name2, bins=30):
    """
    Plota histogramas comparativos de duas s√©ries de dados.
    
    Par√¢metros:
    -----------
    data1 : array ou Series
        Primeira s√©rie de dados
    data2 : array ou Series
        Segunda s√©rie de dados
    name1 : str
        Nome da primeira s√©rie
    name2 : str
        Nome da segunda s√©rie
    bins : int, default=30
        N√∫mero de bins para os histogramas
        
    Retorno:
    --------
    None
    """
    try:
        # Verificar se h√° dados suficientes
        data1_clean = pd.Series(data1).dropna()
        data2_clean = pd.Series(data2).dropna()
        
        if len(data1_clean) == 0 and len(data2_clean) == 0:
            st.warning("N√£o h√° dados dispon√≠veis para criar histogramas")
            return
        
        # Garantir um n√∫mero m√≠nimo de bins se houver poucos dados
        effective_bins1 = min(bins, max(5, len(data1_clean) // 5)) if len(data1_clean) > 0 else bins
        effective_bins2 = min(bins, max(5, len(data2_clean) // 5)) if len(data2_clean) > 0 else bins
        
        fig = go.Figure()
        
        # Adicionar histograma para data1 se houver dados
        if len(data1_clean) > 0:
            fig.add_trace(go.Histogram(
                x=data1_clean,
                name=name1,
                opacity=0.7,
                nbinsx=effective_bins1,
                marker_color='#1f77b4'
            ))
        else:
            st.info(f"N√£o h√° dados dispon√≠veis para {name1}")
        
        # Adicionar histograma para data2 se houver dados
        if len(data2_clean) > 0:
            fig.add_trace(go.Histogram(
                x=data2_clean,
                name=name2,
                opacity=0.7,
                nbinsx=effective_bins2,
                marker_color='#ff7f0e'
            ))
        else:
            st.info(f"N√£o h√° dados dispon√≠veis para {name2}")
    
        # Se n√£o temos dados para nenhum dos dois, retornamos
        if len(data1_clean) == 0 and len(data2_clean) == 0:
            return
      # Atualizar layout
        fig.update_layout(
            title=f"Compara√ß√£o de Distribui√ß√µes: {name1} vs {name2}",
            xaxis_title="Valor",
            yaxis_title="Frequ√™ncia",
            barmode='overlay',
            bargap=0.1,
        )
        
        st.plotly_chart(fig, use_container_width=True)
    except Exception as e:
        st.error(f"Erro ao criar histogramas comparativos: {str(e)}")
        st.info("Verifique se os dados s√£o v√°lidos para visualiza√ß√£o.")


def display_statistical_header():
    """Exibe header informativo da an√°lise estat√≠stica"""
    st.markdown("""
    ### üìä An√°lise Estat√≠stica Avan√ßada de Ativos
    
    Esta se√ß√£o implementa **an√°lises estat√≠sticas sofisticadas** para identificar:
    - **Probabilidades de eventos extremos** (quedas > 10%)
    - **Compara√ß√£o de distribui√ß√µes** entre ativos
    - **Modelos de risco** com distribui√ß√µes t-Student vs Normal
    - **An√°lises de normaliza√ß√£o** e **pair trading estat√≠stico**
    """)


def extreme_analysis_tab(stat_analyzer, df):
    """Tab 1: An√°lise de extremos de ativos"""
    st.subheader("üéØ An√°lise de Extremos de Ativos")
    
    # Sele√ß√£o do ativo
    available_assets = [col for col in df.columns if df[col].dtype in ['float64', 'int64']]
    
    if not available_assets:
        st.error("‚ùå Nenhum ativo num√©rico encontrado no dataset")
        st.info("üí° Execute a p√°gina Home para baixar dados atualizados")
        return
    
    # Configura√ß√µes
    selected_asset, threshold = _setup_extreme_analysis_config(available_assets)
    
    if st.button(f"üìä Analisar Extremos - {selected_asset}"):
        _execute_extreme_analysis(stat_analyzer, selected_asset, threshold)


def _setup_extreme_analysis_config(available_assets):
    """Configura par√¢metros para an√°lise de extremos"""
    col1, col2 = st.columns(2)
    
    with col1:
        selected_asset = st.selectbox(
            "Selecione o ativo para an√°lise:",
            available_assets,
            index=0 if PETR4_SYMBOL not in available_assets else available_assets.index(PETR4_SYMBOL)
        )
    
    with col2:
        threshold = st.slider(
            "Threshold de queda (%):", 
            5.0, 20.0, 10.0, 1.0
        ) / 100
        st.info("üí° An√°lise baseada em distribui√ß√£o emp√≠rica e t-Student")
    
    return selected_asset, threshold


def _execute_extreme_analysis(stat_analyzer, selected_asset, threshold):
    """Executa an√°lise de extremos"""
    with st.spinner("Analisando distribui√ß√µes e extremos..."):
        try:
            # Verificar se o m√©todo extreme_analysis_any_asset existe
            if hasattr(stat_analyzer, 'extreme_analysis_any_asset'):
                extreme_analysis = stat_analyzer.extreme_analysis_any_asset(
                    asset_symbol=selected_asset, 
                    threshold=threshold
                )
            else:
                    # Cria resultado similar ao esperado
                    asset_returns = stat_analyzer.returns[selected_asset].dropna()
                    extreme_falls = asset_returns[asset_returns <= -threshold]
                    extreme_analysis = {
                        'total_days': len(asset_returns),
                        'extreme_falls_count': len(extreme_falls),
                        'probability': len(extreme_falls) / len(asset_returns),
                        'daily_statistics': {
                            'mean': asset_returns.mean(),
                            'std': asset_returns.std(),
                            'skewness': 0,
                            'kurtosis': 0,
                            'min': asset_returns.min(),
                            'max': asset_returns.max()
                        }
                    }
            
            if 'error' not in extreme_analysis:
                _display_extreme_analysis_results(extreme_analysis, selected_asset, threshold)
            else:
                st.error(extreme_analysis['error'])
        except Exception as e:
            st.error(f"Erro na an√°lise: {str(e)}")


def _display_extreme_analysis_results(extreme_analysis, selected_asset, threshold):
    """Exibe resultados da an√°lise de extremos"""
    # M√©tricas principais
    st.subheader(f"üìà M√©tricas de Risco - {selected_asset}")
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        prob_empirical = extreme_analysis.get('probability', 0)
        st.metric(
            f"Prob. Queda > {threshold:.0%}", 
            f"{prob_empirical:.2%}"
        )
    with col2:
        total_days = extreme_analysis.get('total_days', 0)
        extreme_count = extreme_analysis.get('extreme_falls_count', 0)
        st.metric("Eventos Extremos", f"{extreme_count}/{total_days}")
    with col3:
        daily_stats = extreme_analysis.get('daily_statistics', {})
        daily_vol = daily_stats.get('std', 0)
        annual_vol = daily_vol * np.sqrt(252)
        st.metric("Volatilidade Anual", f"{annual_vol:.1%}")
    with col4:
        skewness = daily_stats.get('skewness', 0)
        st.metric("Assimetria", f"{skewness:.2f}")
    
    # Interpreta√ß√£o dos resultados
    _display_extreme_interpretation(prob_empirical, threshold)


def _display_extreme_interpretation(prob_empirical, threshold):
    """Exibe interpreta√ß√£o dos resultados de extremos"""
    st.subheader("üéØ Interpreta√ß√£o dos Resultados")
    
    if prob_empirical > 0.05:  # 5%
        st.warning(f"""
        ‚ö†Ô∏è **Alto Risco**: Probabilidade de {prob_empirical:.1%} para quedas superiores a {threshold:.0%} 
        indica volatilidade elevada. Considere estrat√©gias de hedge.
        """)
    elif prob_empirical > 0.02:  # 2%
        st.info(f"""
        üí° **Risco Moderado**: Probabilidade de {prob_empirical:.1%} √© significativa. 
        Monitore indicadores macro e setoriais.
        """)
    else:
        st.success(f"""
        ‚úÖ **Risco Baixo**: Probabilidade de {prob_empirical:.1%} √© relativamente baixa 
        para quedas extremas no horizonte analisado.
        """)


def distribution_comparison_tab(stat_analyzer):
    """Tab 2: Compara√ß√£o de distribui√ß√µes"""
    st.subheader("üìà Compara√ß√£o Estat√≠stica de Distribui√ß√µes")
    
    # Configura√ß√µes
    st.markdown("### ‚öôÔ∏è Configura√ß√µes da An√°lise")
    
    # Op√ß√µes: busca autom√°tica ou sele√ß√£o manual de ativos
    comparison_option = st.radio(
        "Escolha o m√©todo de compara√ß√£o:",
        ["üîç Busca autom√°tica de pares diferentes", "üëÜ Selecionar ativos manualmente"],
        horizontal=True
    )
    
    if comparison_option == "üîç Busca autom√°tica de pares diferentes":
        # Configura√ß√µes para busca autom√°tica
        min_observations = _setup_distribution_comparison_config()
        
        if st.button("üîç Encontrar Distribui√ß√µes Diferentes"):
            _execute_distribution_comparison(stat_analyzer, min_observations)
    else:
        # Sele√ß√£o manual de dois ativos
        available_assets = sorted(stat_analyzer.returns.columns.tolist())
        
        col1, col2 = st.columns(2)
        with col1:
            asset1 = st.selectbox("Selecione o primeiro ativo:", available_assets, index=0)
        
        # Filtrando o segundo ativo para n√£o ser o mesmo que o primeiro
        filtered_assets = [asset for asset in available_assets if asset != asset1]
        
        with col2:
            asset2 = st.selectbox("Selecione o segundo ativo:", filtered_assets, index=0)
            
        min_observations = st.slider("M√≠nimo de observa√ß√µes:", 100, 1000, 252)
            
        if st.button("üìä Comparar Distribui√ß√µes"):
            _execute_custom_distribution_comparison(stat_analyzer, asset1, asset2, min_observations)


def _setup_distribution_comparison_config():
    """Configura par√¢metros para compara√ß√£o de distribui√ß√µes"""
    col1, col2 = st.columns(2)
    
    with col1:
        min_observations = st.slider("M√≠nimo de observa√ß√µes:", 100, 1000, 252)
    with col2:
        st.info("üí° An√°lise baseada em testes de Kolmogorov-Smirnov e Mann-Whitney U")
    
    return min_observations


def _execute_distribution_comparison(stat_analyzer, min_observations):
    """Executa compara√ß√£o de distribui√ß√µes"""
    with st.spinner("Comparando distribui√ß√µes entre ativos..."):
        try:
            different_pairs_result = stat_analyzer.find_different_distributions(
                min_data_points=min_observations
            )
            
            if different_pairs_result and isinstance(different_pairs_result, dict) and 'error' not in different_pairs_result:
                _display_distribution_comparison_results(stat_analyzer, different_pairs_result)
            else:
                error_msg = different_pairs_result.get('error', 'Nenhum par encontrado') if isinstance(different_pairs_result, dict) else 'Nenhum par encontrado'
                st.info(f"üìä {error_msg}")
                st.info("üí° Tente ajustar o m√≠nimo de observa√ß√µes ou verificar se h√° dados suficientes.")
        except Exception as e:
            st.error(f"‚ùå Erro ao comparar distribui√ß√µes: {str(e)}")
            st.info("üí° Tente ajustar o m√≠nimo de observa√ß√µes ou verificar se h√° dados suficientes.")


def _execute_custom_distribution_comparison(stat_analyzer, asset1, asset2, min_observations):
    """Executa compara√ß√£o de distribui√ß√µes para dois ativos espec√≠ficos selecionados manualmente"""
    with st.spinner(f"Comparando distribui√ß√µes entre {asset1} e {asset2}..."):
        try:
            # Extrair retornos dos dois ativos
            returns1 = stat_analyzer.returns[asset1].dropna() if asset1 in stat_analyzer.returns.columns else pd.Series()
            returns2 = stat_analyzer.returns[asset2].dropna() if asset2 in stat_analyzer.returns.columns else pd.Series()
            
            # Verificar se os ativos existem nos dados
            if returns1.empty or returns2.empty:
                st.error(f"‚ùå Um ou ambos os ativos n√£o foram encontrados nos dados")
                return
            
            # Verificar se h√° dados suficientes
            if len(returns1) < min_observations or len(returns2) < min_observations:
                st.warning(f"‚ö†Ô∏è Um ou ambos os ativos t√™m menos que {min_observations} observa√ß√µes")
                st.info("üí° Os resultados podem n√£o ser estatisticamente significativos")
              # Alinhar as s√©ries temporais
            # Verificar intersec√ß√£o de √≠ndices
            common_index = returns1.index.intersection(returns2.index)
            if len(common_index) < 10:
                st.error(f"‚ùå Dados alinhados insuficientes para an√°lise estat√≠stica")
                st.info(f"Encontrados apenas {len(common_index)} pontos de dados comuns entre os ativos.")
                return
            
            # Filtrar apenas pontos de dados em comum
            aligned_returns1 = returns1.loc[common_index]
            aligned_returns2 = returns2.loc[common_index]
            
            # Verificar se ainda h√° dados ap√≥s filtrar valores NaN
            aligned_data = pd.concat([aligned_returns1, aligned_returns2], axis=1, keys=[asset1, asset2]).dropna()
            
            if aligned_data.empty or aligned_data.shape[0] < 10:
                st.error(f"‚ùå Dados alinhados insuficientes para an√°lise estat√≠stica")
                st.info(f"Encontrados apenas {aligned_data.shape[0]} pontos de dados v√°lidos ap√≥s remover valores NaN.")
                return
                
            # Usar os dados j√° alinhados
            aligned_returns1 = aligned_data[asset1]
            aligned_returns2 = aligned_data[asset2]
            
            # Verifica√ß√£o adicional para valores extremos ou inv√°lidos
            if (aligned_returns1.abs() > 1).any() or (aligned_returns2.abs() > 1).any():
                st.warning("‚ö†Ô∏è Os dados cont√™m valores extremos (retornos superiores a 100%). Verifique os dados de entrada.")
                # Podemos continuar, mas o usu√°rio foi avisado
            
            # Realizar testes estat√≠sticos
            # Teste de Kolmogorov-Smirnov
            ks_statistic, ks_pvalue = stats.ks_2samp(aligned_returns1, aligned_returns2)
            
            # Teste de Mann-Whitney U
            try:
                mw_statistic, mw_pvalue = stats.mannwhitneyu(aligned_returns1, aligned_returns2, alternative='two-sided')
            except ValueError as e:
                st.warning(f"N√£o foi poss√≠vel realizar o teste Mann-Whitney U: {str(e)}")
                mw_statistic, mw_pvalue = 0, 1.0  # Valores padr√£o indicando sem diferen√ßa significativa
            
            # Teste de Levene para igualdade de vari√¢ncias
            try:
                levene_statistic, levene_pvalue = stats.levene(aligned_returns1, aligned_returns2)
            except ValueError as e:
                st.warning(f"N√£o foi poss√≠vel realizar o teste Levene: {str(e)}")
                levene_statistic, levene_pvalue = 0, 1.0  # Valores padr√£o indicando sem diferen√ßa significativa
              # Criar dicion√°rio de resultados
            comparison_tests = {
                'ks_test': {
                    'statistic': ks_statistic,
                    'p_value': ks_pvalue,
                    'significant': ks_pvalue < 0.05
                },
                'mann_whitney': {
                    'statistic': mw_statistic,
                    'p_value': mw_pvalue,
                    'significant': mw_pvalue < 0.05
                },
                'levene': {
                    'statistic': levene_statistic,
                    'p_value': levene_pvalue,
                    'significant': levene_pvalue < 0.05
                }
            }
            
            # Calcular estat√≠sticas descritivas usando as s√©ries alinhadas
            try:
                skew1 = skew(aligned_returns1) if len(aligned_returns1) > 3 else 0
                kurt1 = kurtosis(aligned_returns1) if len(aligned_returns1) > 4 else 0
                skew2 = skew(aligned_returns2) if len(aligned_returns2) > 3 else 0
                kurt2 = kurtosis(aligned_returns2) if len(aligned_returns2) > 4 else 0
            except Exception as e:
                st.warning(f"Erro ao calcular estat√≠sticas de distribui√ß√£o: {str(e)}")
                skew1, kurt1, skew2, kurt2 = 0, 0, 0, 0
            
            descriptive_stats = {
                asset1: {
                    'mean': aligned_returns1.mean(),
                    'median': aligned_returns1.median(),
                    'std': aligned_returns1.std(),
                    'skew': skew1,
                    'kurtosis': kurt1
                },
                asset2: {
                    'mean': aligned_returns2.mean(),
                    'median': aligned_returns2.median(),
                    'std': aligned_returns2.std(),
                    'skew': skew2,
                    'kurtosis': kurt2
                }
            }
            
            # Resultado da compara√ß√£o
            result = {
                'assets': {
                    'asset1': asset1,
                    'asset2': asset2
                },
                'comparison_tests': comparison_tests,
                'descriptive_stats': descriptive_stats,
                'data_points': {
                    asset1: len(returns1),
                    asset2: len(returns2)
                }
            }
            
            # Exibir resultados da compara√ß√£o
            _display_manual_comparison_results(stat_analyzer, result)
            
        except Exception as e:
            st.error(f"‚ùå Erro ao comparar distribui√ß√µes: {str(e)}")
            st.info("üí° Verifique se os ativos selecionados t√™m dados suficientes e v√°lidos.")


def _display_distribution_comparison_results(stat_analyzer, different_pairs_result):
    """Exibe resultados da compara√ß√£o de distribui√ß√µes"""
    st.success("üéØ Encontrado par com distribui√ß√µes estatisticamente diferentes!")
    
    # Exibir resultados da compara√ß√£o
    st.subheader("üìä An√°lise de Distribui√ß√µes Diferentes")
    
    assets = different_pairs_result['assets']
    st.write(f"**Ativos analisados:** {assets['asset1']} vs {assets['asset2']}")
    
    # Testes estat√≠sticos
    _display_statistical_tests(different_pairs_result)
    
    # Estat√≠sticas descritivas
    _display_descriptive_statistics(different_pairs_result, assets)
    
    # Criar gr√°fico de compara√ß√£o
    comparison_plot = stat_analyzer.create_distribution_comparison_plot(
        assets['asset1'], assets['asset2']
    )
    if comparison_plot:
        st.plotly_chart(comparison_plot, use_container_width=True)


def _display_manual_comparison_results(stat_analyzer, result):
    """Exibe resultados da compara√ß√£o manual de distribui√ß√µes"""
    assets = result['assets']
    asset1 = assets['asset1']
    asset2 = assets['asset2']
    
    # Header com resultado principal
    are_different = False
    if 'comparison_tests' in result:
        ks_significant = result['comparison_tests'].get('ks_test', {}).get('significant', False)
        mw_significant = result['comparison_tests'].get('mann_whitney', {}).get('significant', False)
        are_different = ks_significant or mw_significant
    
    if are_different:
        st.success(f"‚úÖ Os ativos {asset1} e {asset2} t√™m distribui√ß√µes estatisticamente diferentes!")
    else:
        st.info(f"‚ÑπÔ∏è N√£o foi encontrada diferen√ßa significativa entre as distribui√ß√µes de {asset1} e {asset2}.")
    
    # Informa√ß√£o sobre os dados
    data_points = result.get('data_points', {})
    st.write(f"**Observa√ß√µes:** {asset1}: {data_points.get(asset1, 'N/A')}, {asset2}: {data_points.get(asset2, 'N/A')}")
    
    # Testes estat√≠sticos
    _display_statistical_tests(result)
    
    # Estat√≠sticas descritivas
    _display_descriptive_statistics(result, assets)
    
    # Visualiza√ß√µes
    st.subheader("üìä Visualiza√ß√µes Comparativas")
    
    # Obter os dados de retornos
    returns1 = stat_analyzer.returns[asset1].dropna()
    returns2 = stat_analyzer.returns[asset2].dropna()
    
    # Histograma de compara√ß√£o
    plot_histogram_comparison(returns1, returns2, asset1, asset2)
    
    # Box plot
    plot_box_comparison(returns1, returns2, asset1, asset2)
    
    # QQ Plot
    plot_qq_comparison(returns1, returns2, asset1, asset2)
    
    # Dispers√£o
    plot_scatter_chart(returns1, returns2, asset1, asset2)
    
    # Interpreta√ß√£o dos resultados
    st.subheader("üí° Interpreta√ß√£o dos Resultados")
    
    if are_different:
        st.markdown(f"""
        **Conclus√£o:** As distribui√ß√µes de retornos de {asset1} e {asset2} s√£o estatisticamente diferentes, 
        o que indica comportamentos de mercado distintos. Isto pode ser relevante para:
        
        - **Diversifica√ß√£o de portfolio**: ativos com comportamentos diferentes ajudam na diversifica√ß√£o
        - **Pair trading**: confirme tamb√©m a cointegra√ß√£o para estrat√©gias de pair trading
        - **Aloca√ß√£o de risco**: o ativo com maior volatilidade deve receber menor aloca√ß√£o para balanceamento
        """)
    else:
        st.markdown(f"""
        **Conclus√£o:** As distribui√ß√µes de {asset1} e {asset2} n√£o apresentaram diferen√ßa estatisticamente 
        significativa, o que sugere comportamentos similares em termos de distribui√ß√£o de retornos.
        
        - **Diversifica√ß√£o limitada**: estes ativos podem oferecer menos benef√≠cios de diversifica√ß√£o
        - **Correla√ß√£o**: verifique a correla√ß√£o entre eles para entender se movem juntos
        - **An√°lise setorial**: podem pertencer ao mesmo setor ou ser afetados pelos mesmos fatores
        """)


def _display_statistical_tests(different_pairs_result):
    """Exibe testes estat√≠sticos"""
    comparison_tests = different_pairs_result.get('comparison_tests', {})
    
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("üß™ Testes Estat√≠sticos")
        
        # Kolmogorov-Smirnov
        if 'ks_test' in comparison_tests:
            ks_test = comparison_tests['ks_test']
            ks_status = "‚úÖ Significativo" if ks_test.get('significant', False) else "‚ùå N√£o significativo"
            st.metric("Teste K-S", f"p = {ks_test.get('p_value', 0):.4f}", ks_status)
        else:
            st.metric("Teste K-S", "N√£o dispon√≠vel")
        
        # Mann-Whitney U
        if 'mann_whitney' in comparison_tests:
            mw_test = comparison_tests['mann_whitney']
            mw_status = "‚úÖ Significativo" if mw_test.get('significant', False) else "‚ùå N√£o significativo"
            st.metric("Mann-Whitney U", f"p = {mw_test.get('p_value', 0):.4f}", mw_status)
        else:
            st.metric("Mann-Whitney U", "N√£o dispon√≠vel")
    
    with col2:
        st.subheader("üìä M√©tricas de Compara√ß√£o")
        
        # KS test
        if 'ks_test' in comparison_tests:
            st.metric(
                "Kolmogorov-Smirnov Test (p-value)",
                f"{comparison_tests['ks_test'].get('p_value', 'N/A'):.4f}",
                help="Testa se duas amostras s√£o da mesma distribui√ß√£o. p-value < 0.05 indica distribui√ß√µes diferentes."
            )
        
        # Anderson-Darling test
        if 'anderson_darling' in comparison_tests:
            st.metric(
                "Anderson-Darling Test",
                f"{comparison_tests['anderson_darling'].get('statistic', 'N/A'):.4f}",
                help="Testa a normalidade. Valores maiores indicam maior desvio da normalidade."
            )
        
        # Mann-Whitney test
        if 'mann_whitney' in comparison_tests:
            st.metric(
                "Mann-Whitney U Test (p-value)",
                f"{comparison_tests['mann_whitney'].get('p_value', 'N/A'):.4f}",
                help="Testa se as medianas s√£o iguais. p-value < 0.05 indica medianas diferentes."
            )
        
        # Levene test
        if 'levene' in comparison_tests:
            st.metric(
                "Levene Test (p-value)",
                f"{comparison_tests['levene'].get('p_value', 'N/A'):.4f}",
                help="Testa se as vari√¢ncias s√£o iguais. p-value < 0.05 indica vari√¢ncias diferentes."
            )


def _display_descriptive_statistics(different_pairs_result, assets):
    """Exibe estat√≠sticas descritivas dos ativos comparados"""
    if 'descriptive_stats' not in different_pairs_result:
        st.warning("‚ö†Ô∏è Estat√≠sticas descritivas n√£o calculadas para este par.")
        return
    
    stats = different_pairs_result['descriptive_stats']
    
    st.subheader("üìà Estat√≠sticas Descritivas")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write(f"**{assets['asset1']}**")
        if assets['asset1'] in stats:
            asset1_stats = stats[assets['asset1']]
            stats_df1 = pd.DataFrame({
                "M√©trica": ["M√©dia", "Mediana", "Desvio Padr√£o", "Assimetria", "Curtose"],
                "Valor": [
                    f"{asset1_stats.get('mean', 'N/A'):.5f}",
                    f"{asset1_stats.get('median', 'N/A'):.5f}",
                    f"{asset1_stats.get('std', 'N/A'):.5f}",
                    f"{asset1_stats.get('skew', 'N/A'):.5f}",
                    f"{asset1_stats.get('kurtosis', 'N/A'):.5f}"
                ]
            })
            st.dataframe(stats_df1, hide_index=True)
        else:
            st.info(f"N√£o h√° estat√≠sticas dispon√≠veis para {assets['asset1']}")
    
    with col2:
        st.write(f"**{assets['asset2']}**")
        if assets['asset2'] in stats:
            asset2_stats = stats[assets['asset2']]
            stats_df2 = pd.DataFrame({
                "M√©trica": ["M√©dia", "Mediana", "Desvio Padr√£o", "Assimetria", "Curtose"],
                "Valor": [
                    f"{asset2_stats.get('mean', 'N/A'):.5f}",
                    f"{asset2_stats.get('median', 'N/A'):.5f}",
                    f"{asset2_stats.get('std', 'N/A'):.5f}",
                    f"{asset2_stats.get('skew', 'N/A'):.5f}",
                    f"{asset2_stats.get('kurtosis', 'N/A'):.5f}"
                ]
            })
            st.dataframe(stats_df2, hide_index=True)
        else:
            st.info(f"N√£o h√° estat√≠sticas dispon√≠veis para {assets['asset2']}")


def plot_correlation_heatmap(returns, selected_assets=None, method='pearson'):
    """
    Plota um mapa de calor de correla√ß√µes entre ativos selecionados.
    
    Par√¢metros:
    -----------
    returns : DataFrame
        DataFrame com retornos dos ativos
    selected_assets : list, opcional
        Lista de ativos para incluir no mapa. Se None, usa todos os ativos.
    method : str, default='pearson'
        M√©todo de correla√ß√£o ('pearson', 'spearman', ou 'kendall')
        
    Retorno:
    --------
    None
    """
    # Filtrar ativos selecionados
    if selected_assets and len(selected_assets) > 0:
        filtered_returns = returns[selected_assets].copy()
    else:
        filtered_returns = returns.copy()
    
    # Verificar se h√° ativos suficientes
    if filtered_returns.shape[1] < 2:
        st.warning("Selecione pelo menos 2 ativos para o mapa de correla√ß√£o.")
        return
    
    # Calcular matriz de correla√ß√£o
    corr_matrix = filtered_returns.corr(method=method)
    
    # Criar mapa de calor
    fig = px.imshow(
        corr_matrix,
        text_auto=True,
        color_continuous_scale='RdBu_r',
        title=f"Mapa de Correla√ß√£o ({method.capitalize()})",
        aspect="auto",
        labels=dict(x="Ativo", y="Ativo", color="Correla√ß√£o")
    )
    
    # Ajustar layout
    fig.update_layout(height=600)
    
    st.plotly_chart(fig, use_container_width=True)


def plot_box_comparison(data1, data2, name1, name2):
    """
    Plota boxplots comparativos de duas s√©ries de dados.
    
    Par√¢metros:
    -----------
    data1 : array ou Series
        Primeira s√©rie de dados
    data2 : array ou Series
        Segunda s√©rie de dados
    name1 : str
        Nome da primeira s√©rie
    name2 : str
        Nome da segunda s√©rie
        
    Retorno:
    --------
    None
    """
    # Criar DataFrame para plotly
    box_df = pd.DataFrame({
        'Valor': pd.concat([pd.Series(data1), pd.Series(data2)]),
        'Ativo': [name1] * len(data1) + [name2] * len(data2)
    })
    
    # Criar boxplot comparativo
    fig = px.box(
        box_df, 
        x='Ativo', 
        y='Valor', 
        title=f"Compara√ß√£o de Boxplots: {name1} vs {name2}",
        color='Ativo'
    )
    
    st.plotly_chart(fig, use_container_width=True)


def plot_qq_comparison(data1, data2, name1, name2):
    """
    Plota gr√°ficos QQ (quantil-quantil) para duas s√©ries de dados.
    
    Par√¢metros:
    -----------
    data1 : array ou Series
        Primeira s√©rie de dados
    data2 : array ou Series
        Segunda s√©rie de dados
    name1 : str
        Nome da primeira s√©rie
    name2 : str
        Nome da segunda s√©rie
        
    Retorno:
    --------
    None
    """
    # Verifica√ß√£o inicial de dados
    if isinstance(data1, (list, np.ndarray)) and len(data1) == 0:
        st.warning(f"N√£o h√° dados dispon√≠veis para {name1}")
        return
    
    if isinstance(data2, (list, np.ndarray)) and len(data2) == 0:
        st.warning(f"N√£o h√° dados dispon√≠veis para {name2}")
        return
    
    # Criar duas subplots
    fig = make_subplots(rows=1, cols=2, 
                        subplot_titles=[f"QQ Plot - {name1}", f"QQ Plot - {name2}"])
      # Calcular quantis te√≥ricos (distribui√ß√£o normal)
    from scipy import stats    # QQ plot para data1
    data1_clean = pd.Series(data1).dropna()
    if len(data1_clean) > 2:  # Necess√°rio pelo menos 3 pontos
        try:
            # Verificar se h√° valores v√°lidos suficientes ap√≥s limpeza
            if data1_clean.isnull().all() or len(data1_clean) == 0:
                st.warning(f"N√£o h√° dados v√°lidos para {name1} ap√≥s remover valores NaN")
                has_plot1 = False
            else:
                qq_plot_asset1 = stats.probplot(data1_clean, dist="norm", fit=True)
                theoretical_quantiles_asset1, ordered_values_asset1 = qq_plot_asset1[0]
                (regression_slope_asset1, regression_intercept_asset1, correlation_coef_asset1) = qq_plot_asset1[1]  # Corrigido para atribuir todos os valores retornados
                
                fig.add_trace(
                    go.Scatter(
                        x=theoretical_quantiles_asset1,
                        y=ordered_values_asset1,
                        mode='markers',
                        name=name1,
                        marker=dict(color='blue')
                    ),
                    row=1, col=1
                )
                
                # Adicionar linha de refer√™ncia
                fig.add_trace(
                    go.Scatter(
                        x=theoretical_quantiles_asset1,
                        y=regression_intercept_asset1 + regression_slope_asset1 * theoretical_quantiles_asset1,
                        mode='lines',
                        name='Refer√™ncia Normal',
                        line=dict(color='red')
                    ),
                    row=1, col=1
                )
                has_plot1 = True
        except Exception as e:
            st.warning(f"Erro ao plotar QQ para {name1}: {str(e)}")
            has_plot1 = False
    else:
        st.warning(f"Dados insuficientes para {name1}. Necess√°rio pelo menos 3 pontos.")
        has_plot1 = False
              # QQ plot para data2
    data2_clean = pd.Series(data2).dropna()
    if len(data2_clean) > 2:  # Necess√°rio pelo menos 3 pontos
        try:
            # Verificar se h√° valores v√°lidos suficientes ap√≥s limpeza
            if data2_clean.isnull().all() or len(data2_clean) == 0:
                st.warning(f"N√£o h√° dados v√°lidos para {name2} ap√≥s remover valores NaN")
                has_plot2 = False
            else:
                qq_plot_asset2 = stats.probplot(data2_clean, dist="norm", fit=True)
                theoretical_quantiles_asset2, ordered_values_asset2 = qq_plot_asset2[0]
                (regression_slope_asset2, regression_intercept_asset2, correlation_coef_asset2) = qq_plot_asset2[1]  # Corrigido para atribuir todos os valores retornados
                
                fig.add_trace(
                    go.Scatter(
                        x=theoretical_quantiles_asset2,
                        y=ordered_values_asset2,
                        mode='markers',
                        name=name2,
                        marker=dict(color='green')
                    ),
                    row=1, col=2
                )
                
                # Adicionar linha de refer√™ncia
                fig.add_trace(
                    go.Scatter(
                        x=theoretical_quantiles_asset2,
                        y=regression_intercept_asset2 + regression_slope_asset2 * theoretical_quantiles_asset2,
                        mode='lines',
                        name='Refer√™ncia Normal',
                        line=dict(color='red')
                    ),
                    row=1, col=2
                )
                has_plot2 = True
        except Exception as e:
            st.warning(f"Erro ao plotar QQ para {name2}: {str(e)}")
            has_plot2 = False
    else:
        st.warning(f"Dados insuficientes para {name2}. Necess√°rio pelo menos 3 pontos.")
        has_plot2 = False    # Verificar se pelo menos um gr√°fico foi criado
    if has_plot1 or has_plot2:
        # Atualizar layout
        fig.update_layout(
            title="Gr√°ficos QQ (Teste de Normalidade)",
            height=500,
            showlegend=False
        )
        
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.error("‚ö†Ô∏è N√£o foi poss√≠vel criar nenhum gr√°fico QQ com os dados fornecidos.")

def display_distribution_comparison_metrics(comparison_tests):
    """
    Exibe m√©tricas de compara√ß√£o entre duas distribui√ß√µes.
    
    Par√¢metros:
    -----------
    comparison_tests : dict
        Dicion√°rio com resultados dos testes estat√≠sticos
        
    Retorno:
    --------
    None
    """
    if not comparison_tests:
        st.warning("N√£o h√° dados suficientes para compara√ß√£o estat√≠stica.")
        return
    
    st.subheader("üìä M√©tricas de Compara√ß√£o")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # KS test
        if 'ks_test' in comparison_tests:
            st.metric(
                "Kolmogorov-Smirnov Test (p-value)",
                f"{comparison_tests['ks_test'].get('p_value', 'N/A'):.4f}",
                help="Testa se duas amostras s√£o da mesma distribui√ß√£o. p-value < 0.05 indica distribui√ß√µes diferentes."
            )
        
        # Anderson-Darling test
        if 'anderson_darling' in comparison_tests:
            st.metric(
                "Anderson-Darling Test",
                f"{comparison_tests['anderson_darling'].get('statistic', 'N/A'):.4f}",
                help="Testa a normalidade. Valores maiores indicam maior desvio da normalidade."
            )
    
    with col2:
        # Mann-Whitney test
        if 'mann_whitney' in comparison_tests:
            st.metric(
                "Mann-Whitney U Test (p-value)",
                f"{comparison_tests['mann_whitney'].get('p_value', 'N/A'):.4f}",
                help="Testa se as medianas s√£o iguais. p-value < 0.05 indica medianas diferentes."
            )
        
        # Levene test
        if 'levene' in comparison_tests:
            st.metric(
                "Levene Test (p-value)",
                f"{comparison_tests['levene'].get('p_value', 'N/A'):.4f}",
                help="Testa se as vari√¢ncias s√£o iguais. p-value < 0.05 indica vari√¢ncias diferentes."
            )


def risk_models_tab(stat_analyzer, df):
    """
    Tab 3: Modelos de Risco
    
    Implementa√ß√£o de modelos de risco financeiro, incluindo an√°lises de distribui√ß√£o de retornos
    com suporte para distribui√ß√µes t-Student e metodologia avan√ßada para eventos extremos.
    
    Inclui an√°lise especial para Petrobras com a implementa√ß√£o da metodologia
    de eventos extremos desenvolvida pelo Prof. Carlos Alberto Rodrigues (UEFS).
    """
    st.subheader("üî¨ Modelos de Risco")
    

    
    # Sele√ß√£o do ativo para an√°lise de risco
    available_assets = [col for col in df.columns if df[col].dtype in ['float64', 'int64']]
    
    if not available_assets:
        st.error("‚ùå Nenhum ativo num√©rico dispon√≠vel para an√°lise")
        return
    
    # Configura√ß√µes da an√°lise
    col1, col2 = st.columns(2)
    
    with col1:
        selected_asset = st.selectbox(
            "Selecione o ativo para an√°lise de risco:",
            available_assets
        )
    
    with col2:
        confidence_level = st.slider(
            "N√≠vel de confian√ßa (%)",
            min_value=90.0,
            max_value=99.0,
            value=95.0,
            step=0.5,
            help="N√≠vel de confian√ßa para c√°lculos de risco (VaR, CVaR)"
        )
      # Configura√ß√£o de an√°lise
    show_petr4_analysis = False
    
    # An√°lise de Modelos de Risco
    if st.button("üîé Analisar Risco"):
        _execute_risk_analysis(stat_analyzer, df, selected_asset, confidence_level, show_petr4_analysis)


def _execute_risk_analysis(stat_analyzer, df, selected_asset, confidence_level, show_petr4_analysis):
    """Executa an√°lise de risco"""
    with st.spinner(f"Analisando risco do ativo {selected_asset}..."):
        try:
            # Extrair retornos
            returns = df[selected_asset].pct_change().dropna()
            
            # Estat√≠sticas b√°sicas
            mean_return = returns.mean()
            std_return = returns.std()
            skewness = returns.skew()
            kurt = returns.kurtosis()
            
            # C√°lculo de VaR e CVaR
            alpha = 1 - (confidence_level / 100.0)
            var_normal = mean_return + std_return * stats.norm.ppf(alpha)
            var_empirical = returns.quantile(alpha)
            
            # CVaR (Expected Shortfall)
            cvar_empirical = returns[returns <= var_empirical].mean()
            
            # Calcular m√°ximo drawdown
            equity_curve = (1 + returns).cumprod()
            running_max = equity_curve.expanding().max()
            drawdown = (equity_curve / running_max - 1)
            max_drawdown = drawdown.min()
            
            # VaR e CVaR usando distribui√ß√£o t de Student
            try:
                t_params = stats.t.fit(returns)
                df_param, loc_param, scale_param = t_params
                var_t = loc_param + scale_param * stats.t.ppf(alpha, df_param)
            except Exception:
                var_t = var_normal  # Fallback para o VaR normal
            
            # Exibir resultados
            risk_metrics = {
                'mean_return': mean_return,
                'std_return': std_return,
                'skewness': skewness,
                'kurtosis': kurt,
                'var_normal': var_normal,
                'var_empirical': var_empirical,
                'var_t': var_t,
                'cvar_empirical': cvar_empirical,
                'confidence_level': confidence_level,
                'max_drawdown': max_drawdown
            }
            
            _display_risk_analysis_results(selected_asset, risk_metrics)
            
            # Visualiza√ß√µes
            _display_distribution_comparison_plots(returns, selected_asset)
            
            # Preparar dados para interpreta√ß√£o de risco
            risk_metrics_for_interp = {
                'var_cvar': {
                    'var_95': var_empirical,
                    'var_99': returns.quantile(0.01),  # VaR a 99%
                    'cvar_95': cvar_empirical,
                    'cvar_99': returns[returns <= returns.quantile(0.01)].mean()  # CVaR a 99%
                },
                'volatility_analysis': {
                    'current_vol_annual': std_return * np.sqrt(252)
                },
                'risk_metrics': {
                    'max_drawdown': max_drawdown
                }
            }
            
            # Exibir interpreta√ß√£o de risco
            _display_risk_interpretation(risk_metrics_for_interp)
              
            # An√°lise de eventos extremos
            if show_petr4_analysis and selected_asset == PETR4_SYMBOL:
                _display_asset_extreme_analysis(stat_analyzer, df)
                
        except Exception as e:
            st.error(f"Erro na an√°lise: {str(e)}")
            import traceback
            st.error(f"Detalhe: {traceback.format_exc()}")


def _display_risk_analysis_results(selected_asset, risk_metrics):
    """Exibe resultados da an√°lise de risco"""
    st.subheader(f"üìä M√©tricas de Risco - {selected_asset}")
    
    # Formatar m√©tricas para exibi√ß√£o
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "VaR Emp√≠rico", 
            f"{risk_metrics['var_empirical']*100:.2f}%",
            help=f"Value at Risk emp√≠rico (n√≠vel de confian√ßa: {risk_metrics['confidence_level']}%)"
        )
    
    with col2:
        st.metric(
            "CVaR Emp√≠rico", 
            f"{risk_metrics['cvar_empirical']*100:.2f}%",
            help="Conditional Value at Risk (Expected Shortfall)"
        )
    
    with col3:
        st.metric(
            "VaR Normal", 
            f"{risk_metrics['var_normal']*100:.2f}%",
            help="Value at Risk assumindo distribui√ß√£o Normal"
        )
    
    with col4:
        st.metric(
            "VaR t-Student", 
            f"{risk_metrics['var_t']*100:.2f}%",
            help="Value at Risk usando distribui√ß√£o t de Student"
        )
    
    # Segunda linha de m√©tricas
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Volatilidade Anual", f"{risk_metrics['std_return'] * np.sqrt(252) * 100:.1f}%")
    
    with col2:
        st.metric("Retorno M√©dio", f"{risk_metrics['mean_return']*100:.2f}%")
    
    with col3:
        # Interpreta√ß√£o da assimetria
        skew_desc = "Sim√©trica"
        if risk_metrics['skewness'] > 0.5:
            skew_desc = "Ass. Positiva"
        elif risk_metrics['skewness'] < -0.5:
            skew_desc = "Ass. Negativa"
            
        st.metric("Assimetria", f"{risk_metrics['skewness']:.2f}", skew_desc)
    
    with col4:
        # Interpreta√ß√£o da curtose
        kurt_desc = "Normal"
        if risk_metrics['kurtosis'] > 1:
            kurt_desc = "Caudas Pesadas"
        elif risk_metrics['kurtosis'] < -1:
            kurt_desc = "Caudas Leves"
            
        st.metric("Curtose", f"{risk_metrics['kurtosis']:.2f}", kurt_desc)
    
    # Interpreta√ß√£o dos resultados
    _display_risk_interpretation(risk_metrics)


def _display_distribution_comparison_plots(returns, selected_asset):
    """Cria gr√°ficos comparativos de distribui√ß√µes de retornos normais vs emp√≠ricas"""
    st.subheader("üìà Compara√ß√£o de Distribui√ß√µes")
    
    # Criar distribui√ß√µes te√≥ricas para compara√ß√£o
    mean = returns.mean()
    std = returns.std()
    
    # Valores para plotagem
    x_range = np.linspace(returns.min(), returns.max(), 100)
    pdf_normal = stats.norm.pdf(x_range, mean, std)
    
    # Ajustar t-student
    t_params = stats.t.fit(returns)
    df_param, loc_param, scale_param = t_params
    pdf_t = stats.t.pdf(x_range, df_param, loc_param, scale_param)
    
    # Gr√°fico de distribui√ß√£o
    fig = go.Figure()
    
    # Histograma dos retornos
    fig.add_trace(go.Histogram(
        x=returns,
        histnorm='probability density',
        name='Retornos Emp√≠ricos',
        opacity=0.7,
        nbinsx=30,
    ))
    
    # Curva normal
    fig.add_trace(go.Scatter(
        x=x_range,
        y=pdf_normal,
        mode='lines',
        name='Normal',
        line=dict(color='red')
    ))
    
    # Curva t-student
    fig.add_trace(go.Scatter(
        x=x_range,
        y=pdf_t,
        mode='lines',
        name=f't-Student (df={df_param:.1f})',
        line=dict(color='green')
    ))
    
    # Layout do gr√°fico
    fig.update_layout(
        title=f"Distribui√ß√£o de Retornos: {selected_asset}",
        xaxis_title="Retorno",
        yaxis_title="Densidade",
        legend_title="Distribui√ß√µes",
        height=500
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # QQ Plot
    qq_fig = make_subplots(rows=1, cols=2, subplot_titles=["QQ Plot (Normal)", "QQ Plot (t-Student)"])
    
    # QQ Plot para distribui√ß√£o normal
    theoretical_quantiles, ordered_values = stats.probplot(returns, dist='norm', fit=False)
    qq_fig.add_trace(
        go.Scatter(
            x=theoretical_quantiles,
            y=ordered_values,
            mode='markers',
            name='Dados',
            marker=dict(size=4)
        ),
        row=1, col=1
    )
    
    # Linha de refer√™ncia (y=x)
    min_val = min(theoretical_quantiles)
    max_val = max(theoretical_quantiles)
    qq_fig.add_trace(
        go.Scatter(
            x=[min_val, max_val],
            y=[min_val, max_val],
            mode='lines',
            name='Refer√™ncia',
            line=dict(color='red', dash='dash')
        ),
        row=1, col=1
    )
    
    # QQ Plot para t-student
    t_quantiles = stats.t.ppf(np.linspace(0.01, 0.99, len(returns)), df_param)
    t_quantiles = (t_quantiles - t_quantiles.mean()) / t_quantiles.std() * returns.std() + returns.mean()
    
    qq_fig.add_trace(
        go.Scatter(
            x=t_quantiles,
            y=np.sort(returns),
            mode='markers',
            name='Dados',
            marker=dict(size=4)
        ),
        row=1, col=2
    )
    
    # Linha de refer√™ncia para t-student
    min_t = min(t_quantiles)
    max_t = max(t_quantiles)
    qq_fig.add_trace(
        go.Scatter(
            x=[min_t, max_t],
            y=[min(returns), max(returns)],
            mode='lines',
            name='Refer√™ncia',
            line=dict(color='red', dash='dash')
        ),
        row=1, col=2
    )
    
    qq_fig.update_layout(
        height=400,
        title_text="QQ Plots - Avalia√ß√£o da Normalidade"
    )
    
    st.plotly_chart(qq_fig, use_container_width=True)


def _display_risk_interpretation(risk_metrics):
    """Exibe interpreta√ß√£o dos resultados da an√°lise de risco"""
    st.subheader("üí° Interpreta√ß√£o dos Resultados de Risco")
    
    # Obter valores das m√©tricas principais
    var_95 = risk_metrics.get('var_cvar', {}).get('var_95', 0)
    var_99 = risk_metrics.get('var_cvar', {}).get('var_99', 0)
    cvar_95 = risk_metrics.get('var_cvar', {}).get('cvar_95', 0)
    
    # M√©tricas adicionais
    max_dd = risk_metrics.get('risk_metrics', {}).get('max_drawdown', 0)
    vol_anual = risk_metrics.get('volatility_analysis', {}).get('current_vol_annual', 0)
    
    # Criar tabela de interpreta√ß√£o
    interpretation_df = pd.DataFrame({
        "M√©trica": ["Value at Risk (95%)", "Conditional VaR (95%)", "M√°ximo Drawdown", "Volatilidade Anualizada"],
        "Valor": [f"{var_95:.2%}", f"{cvar_95:.2%}", f"{max_dd:.2%}", f"{vol_anual:.2%}"],
        "Interpreta√ß√£o": [
            f"Em 95% dos casos, a perda di√°ria n√£o ultrapassar√° {abs(var_95):.2%}",
            f"Em caso de evento extremo (5% piores dias), a perda m√©dia √© de {abs(cvar_95):.2%}",
            f"A maior queda hist√≥rica do ativo foi de {abs(max_dd):.2%}",
            f"A volatilidade anualizada do ativo √© {vol_anual:.2%}"
        ]
    })
    
    # Mostrar a tabela
    st.table(interpretation_df)
    
    # Avalia√ß√£o de risco
    risk_score = _calculate_risk_score(var_95, cvar_95, max_dd, vol_anual)
    risk_category = _get_risk_category(risk_score)
    
    # Exibir categoria de risco
    st.markdown(f"### Classifica√ß√£o de Risco: {risk_category['color']} {risk_category['level']}")
    
    # Recomenda√ß√µes
    st.markdown("#### Recomenda√ß√µes:")
    for suggestion in risk_category['suggestions']:
        st.markdown(f"- {suggestion}")


def _calculate_risk_score(var_95, cvar_95, max_dd, vol_anual):
    """Calcula pontua√ß√£o de risco baseada nas m√©tricas"""
    var_score = min(abs(var_95) * 50, 5)  # Pontuar at√© 5 baseado no VaR
    cvar_score = min(abs(cvar_95) * 30, 5)  # Pontuar at√© 5 baseado no CVaR
    dd_score = min(abs(max_dd) * 10, 5)  # Pontuar at√© 5 baseado no M√°ximo Drawdown
    vol_score = min(vol_anual * 10, 5)  # Pontuar at√© 5 baseado na volatilidade
    
    # M√©dia ponderada das pontua√ß√µes
    risk_score = (var_score * 0.25 + cvar_score * 0.30 + 
                 dd_score * 0.25 + vol_score * 0.20)
    return risk_score


def _get_risk_category(risk_score):
    """Retorna categoria de risco baseada na pontua√ß√£o"""
    if risk_score <= 1.5:
        return {
            'level': "MUITO BAIXO",
            'color': "üü¢",
            'recommendation': "Ativo de baixo risco",
            'suggestions': ["Adequado para perfil conservador", "Pode compor a base do portf√≥lio"]
        }
    elif risk_score <= 2.5:
        return {
            'level': "BAIXO", 
            'color': "üü°",
            'recommendation': "Ativo adequado para perfil moderadamente conservador",
            'suggestions': ["Pode compor 40-60% do portf√≥lio", "Adequado para diversifica√ß√£o"]
        }
    elif risk_score <= 3.5:
        return {
            'level': "MODERADO",
            'color': "üü†", 
            'recommendation': "Ativo de risco equilibrado",
            'suggestions': ["Limite a 30-40% do portf√≥lio", "Implemente stop-loss em -15%"]
        }
    elif risk_score <= 4.5:
        return {
            'level': "ALTO",
            'color': "üî¥",
            'recommendation': "Ativo de alto risco, apenas para perfil arrojado", 
            'suggestions': ["Limite a 15-25% do portf√≥lio", "Stop-loss obrigat√≥rio"]
        }
    else:
        return {
            'level': "MUITO ALTO",
            'color': "üö´",
            'recommendation': "Ativo de risco extremo",
            'suggestions': ["M√°ximo 5-10% do portf√≥lio", "Monitoramento intraday necess√°rio"]
        }


def advanced_pair_trading_tab(df):
    """
    Tab 4: Pair Trading Avan√ßado
    
    Implementa an√°lise estat√≠stica avan√ßada para pares de trading,
    incluindo testes de cointegra√ß√£o, an√°lise de res√≠duos e modelagem
    estat√≠stica para estrat√©gias de pair trading.
    """
    st.subheader("üîÑ Pair Trading Avan√ßado")
    
    st.markdown("""
    ### üìä An√°lise Estat√≠stica para Pair Trading
    
    Esta se√ß√£o implementa an√°lises avan√ßadas para encontrar pares de ativos
    adequados para estrat√©gias de pair trading estat√≠stico.
    """)
    
    # Verificar se h√° dados suficientes
    if df is None or df.empty or df.shape[1] < 2:
        st.error("‚ùå Dados insuficientes para an√°lise de pair trading")
        st.info("üìà √â necess√°rio ter pelo menos 2 ativos para an√°lise de pares")
        return
    
    # Sele√ß√£o de ativos
    st.markdown("### ‚öôÔ∏è Configura√ß√µes de An√°lise")
    
    col1, col2 = st.columns(2)
    
    with col1:
        asset1 = st.selectbox(
            "Selecione o primeiro ativo:",
            df.columns,
            key="pair_trading_asset1"
        )
    
    with col2:
        remaining_assets = [asset for asset in df.columns if asset != asset1]
        asset2 = st.selectbox(
            "Selecione o segundo ativo:",
            remaining_assets,
            key="pair_trading_asset2"
        )
    
    # Sele√ß√£o do per√≠odo para an√°lise
    start_date = st.date_input(
        "Data inicial para an√°lise:",
        value=df.index[0].date() if not df.empty and len(df.index) > 0 else None,
        min_value=df.index[0].date() if not df.empty and len(df.index) > 0 else None,
        max_value=df.index[-1].date() if not df.empty and len(df.index) > 0 else None
    )
    
    # Bot√£o para executar an√°lise
    if st.button("üîç Analisar Par"):
        with st.spinner("Realizando an√°lise estat√≠stica do par..."):
            try:
                # Extrair dados do par
                pair_data = df[[asset1, asset2]].copy()
                
                # Filtrar por data
                if start_date:
                    pair_data = pair_data[pair_data.index.date >= start_date]
                
                # Calcular retornos
                returns_data = pair_data.pct_change().dropna()
                
                # Verificar se h√° dados suficientes
                if len(returns_data) < 30:
                    st.error("‚ùå Dados insuficientes para an√°lise robusta")
                    st.info("üìä Recomendamos pelo menos 30 observa√ß√µes")
                    return
                
                # Exibir an√°lise do par
                _display_pair_analysis(pair_data, returns_data, asset1, asset2)
                
            except Exception as e:
                st.error(f"‚ùå Erro na an√°lise: {str(e)}")


def _display_pair_analysis(price_data, returns_data, asset1, asset2):
    """Exibe resultados da an√°lise de par trading"""
    st.subheader(f"üìä An√°lise do Par: {asset1} vs {asset2}")
    
    # Valida√ß√£o abrangente dos dados para pre√ßo
    is_valid_price, price_message = validate_data_for_operations(
        price_data, 
        operation_name="an√°lise de pre√ßos", 
        min_samples=10, 
        check_columns=[asset1, asset2]
    )
    
    if not is_valid_price:
        st.error(price_message)
        st.info("üìä Verifique se o per√≠odo selecionado cont√©m dados v√°lidos")
        return
    elif "‚ö†Ô∏è" in price_message:
        st.warning(price_message)
    
    # Valida√ß√£o abrangente dos dados para retornos
    is_valid_returns, returns_message = validate_data_for_operations(
        returns_data, 
        operation_name="an√°lise de retornos", 
        min_samples=10, 
        check_columns=[asset1, asset2]
    )
    
    if not is_valid_returns:
        st.error(returns_message)
        st.info("üìä Os c√°lculos de retornos podem ser afetados por problemas nos dados")
    elif "‚ö†Ô∏è" in returns_message:
        st.warning(returns_message)
    
    try:
        # Gr√°fico de pre√ßos normalizados
        st.markdown("### üìà Evolu√ß√£o de Pre√ßos Normalizados")
        
        # Verifica valores ausentes ou inv√°lidos antes da normaliza√ß√£o
        if price_data.iloc[0].isna().any() or (price_data.iloc[0] == 0).any():
            st.warning("‚ö†Ô∏è Valores iniciais ausentes ou zero. Usando os primeiros valores v√°lidos para normaliza√ß√£o.")
            first_valid = price_data.apply(lambda x: x.first_valid_index())
            normalized_prices = pd.DataFrame(index=price_data.index)
            for col in price_data.columns:
                idx = first_valid[col]
                if idx is not None and price_data.loc[idx, col] != 0:
                    normalized_prices[col] = price_data[col] / price_data.loc[idx, col] * 100
                else:
                    normalized_prices[col] = np.nan
                    st.warning(f"‚ùå N√£o foi poss√≠vel normalizar {col} devido a valores ausentes ou zero")
        else:
            # Normalizar pre√ßos
            normalized_prices = price_data.div(price_data.iloc[0]) * 100
        
        # Plotar gr√°fico de pre√ßos normalizados
        fig_prices = px.line(
            normalized_prices, 
            title=f"Pre√ßos Normalizados: {asset1} vs {asset2}"
        )
        st.plotly_chart(fig_prices, use_container_width=True)
    except Exception as e:
        st.error(f"‚ùå Erro ao criar gr√°fico de pre√ßos normalizados: {str(e)}")
        st.info("üìä Verifique se os dados de pre√ßo s√£o v√°lidos")
    # Correla√ß√£o e estat√≠sticas
    st.markdown("### üìä M√©tricas Estat√≠sticas")
    
    # Verificar se h√° dados v√°lidos para c√°lculos
    valid_data = returns_data.dropna()
    if valid_data.empty or len(valid_data) < 2:
        st.error("‚ùå Dados insuficientes para calcular m√©tricas estat√≠sticas")
        return
        
    try:
        # Verifica se as colunas existem nos dados
        if asset1 not in valid_data.columns or asset2 not in valid_data.columns:
            st.error(f"‚ùå Colunas {asset1} ou {asset2} n√£o encontradas nos dados")
            return
            
        # Verificar dados ausentes
        if valid_data[asset1].isna().any() or valid_data[asset2].isna().any():
            st.warning("‚ö†Ô∏è H√° valores ausentes nos dados. Removendo para c√°lculos.")
            valid_data = valid_data.dropna(subset=[asset1, asset2])
            
        # Verificar tamanho dos dados depois da remo√ß√£o de valores ausentes
        if len(valid_data) < 2:
            st.error("‚ùå Dados insuficientes ap√≥s remo√ß√£o de valores ausentes")
            return
            
        # Calcular correla√ß√£o com tratamento de erro
        try:
            corr = valid_data[asset1].corr(valid_data[asset2])
            if np.isnan(corr):
                corr = np.nan
                st.warning("‚ö†Ô∏è N√£o foi poss√≠vel calcular correla√ß√£o v√°lida")
        except Exception:
            corr = np.nan
            st.warning("‚ö†Ô∏è Erro ao calcular correla√ß√£o")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Correla√ß√£o", f"{corr:.3f}" if not np.isnan(corr) else "N/A")
        
        with col2:
            try:
                # C√°lculo do beta com verifica√ß√µes adicionais
                asset2_var = valid_data[asset2].var()
                if asset2_var > 0 and len(valid_data) >= 2:
                    cov_matrix = np.cov(valid_data[asset1], valid_data[asset2])
                    if cov_matrix.shape == (2, 2): # Verifica√ß√£o adicional da matriz de covari√¢ncia
                        beta = cov_matrix[0, 1] / asset2_var
                        st.metric("Beta", f"{beta:.3f}" if not np.isnan(beta) else "N/A")
                    else:
                        st.metric("Beta", "N/A")
                        st.warning("‚ö†Ô∏è Matriz de covari√¢ncia inv√°lida")
                else:
                    st.metric("Beta", "N/A")
                    st.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel calcular o Beta: vari√¢ncia de {asset2} √© zero ou insuficiente")
            except Exception as e:
                st.metric("Beta", "N/A")
                st.warning(f"‚ö†Ô∏è Erro no c√°lculo do Beta: {str(e)}")
        
        with col3:            
            try:
                # Verifica√ß√£o para c√°lculo da raz√£o de pre√ßos
                if not price_data.empty and price_data[asset2].iloc[-1] != 0:
                    # Verificar valores NaN
                    if not (np.isnan(price_data[asset1].iloc[-1]) or np.isnan(price_data[asset2].iloc[-1])):
                        ratio = price_data[asset1].iloc[-1] / price_data[asset2].iloc[-1]
                        st.metric("Raz√£o de Pre√ßos", f"{ratio:.3f}" if not np.isnan(ratio) else "N/A")
                    else:
                        st.metric("Raz√£o de Pre√ßos", "N/A")
                        st.warning("‚ö†Ô∏è Valores ausentes nos √∫ltimos pre√ßos")
                else:
                    st.metric("Raz√£o de Pre√ßos", "N/A")
                    st.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel calcular a raz√£o de pre√ßos: √∫ltimo valor de {asset2} √© zero ou ausente")
            except Exception as e:
                st.metric("Raz√£o de Pre√ßos", "N/A")
                st.warning(f"‚ö†Ô∏è Erro no c√°lculo da raz√£o de pre√ßos: {str(e)}")
    except Exception as e:
        st.error(f"‚ùå Erro ao calcular m√©tricas estat√≠sticas: {str(e)}")
        st.info("üìä Verifique se os dados s√£o v√°lidos e cont√™m informa√ß√µes suficientes")
    
    # Gr√°ficos adicionais
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### üìä Dispers√£o de Retornos")
        plot_scatter_chart(returns_data[asset1], returns_data[asset2], asset1, asset2)
    
    with col2:
        st.markdown("### üìä Compara√ß√£o de Distribui√ß√µes")
        plot_histogram_comparison(returns_data[asset1], returns_data[asset2], asset1, asset2)
    # Testes estat√≠sticos
    st.markdown("### üß™ Testes Estat√≠sticos")
    
    # Inicializa as vari√°veis com valores padr√£o
    coint_pvalue = np.nan
    half_life = np.nan
    adf_pvalue = np.nan
    
    try:
        # Verifica√ß√£o inicial abrangente dos dados
        if price_data.empty:
            st.error("‚ùå N√£o h√° dados dispon√≠veis para testes estat√≠sticos")
            return
            
        # Verificar dados ausentes e zeros (que podem causar problemas)
        missing_data = price_data.isnull().sum()
        zero_values = (price_data == 0).sum()
        
        if missing_data.any() or zero_values.any():
            st.warning(f"‚ö†Ô∏è Dados cont√™m valores ausentes ({missing_data.sum()}) ou zeros ({zero_values.sum()})")
        
        # Verificar se h√° dados suficientes para testes estat√≠sticos
        if len(price_data) < 30:
            st.warning(f"‚ö†Ô∏è Dados insuficientes para testes estat√≠sticos robustos (m√≠nimo recomendado: 30, atual: {len(price_data)})")
            return
        
        # Verificar se as colunas existem
        if asset1 not in price_data.columns or asset2 not in price_data.columns:
            st.error(f"‚ùå Colunas necess√°rias n√£o encontradas: {asset1} ou {asset2}")
            return
            
        # Remover valores ausentes para evitar problemas em c√°lculos
        clean_data = price_data[[asset1, asset2]].dropna()
        if len(clean_data) < 30:
            st.warning(f"‚ö†Ô∏è Ap√≥s remover valores ausentes, restaram apenas {len(clean_data)} observa√ß√µes (m√≠nimo recomendado: 30)")
            return
            
        # Verificar vari√¢ncia zero (dados constantes)
        if clean_data[asset1].var() == 0 or clean_data[asset2].var() == 0:
            st.warning("‚ö†Ô∏è Um ou ambos os ativos t√™m vari√¢ncia zero (pre√ßos constantes)")
            return
            
        # Preparar dados para testes com tratamento de erro
        try:
            X = sm.add_constant(clean_data[asset2])
            model = sm.OLS(clean_data[asset1], X).fit()
        except Exception as e:
            st.error(f"‚ùå Erro ao criar modelo OLS: {str(e)}")
            return
            
        # Teste de cointegra√ß√£o com valida√ß√µes
        try:
            # Verificar se h√° dados suficientes e sem valores ausentes
            if len(clean_data[asset1]) > 30 and len(clean_data[asset2]) > 30:
                # Verificar se os dados n√£o s√£o constantes
                if np.std(clean_data[asset1]) > 1e-8 and np.std(clean_data[asset2]) > 1e-8:
                    coint_result = sm.tsa.stattools.coint(clean_data[asset1], clean_data[asset2])
                    coint_pvalue = coint_result[1]
                    
                    # Validar resultado da cointegra√ß√£o
                    if not np.isfinite(coint_pvalue):
                        st.warning("‚ö†Ô∏è Resultado do teste de cointegra√ß√£o √© um valor n√£o finito")
                        coint_pvalue = np.nan
                else:
                    st.warning("‚ö†Ô∏è Dados com desvio padr√£o pr√≥ximo de zero - teste de cointegra√ß√£o n√£o confi√°vel")
            else:
                st.warning("‚ö†Ô∏è Dados insuficientes para teste de cointegra√ß√£o")
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Erro no teste de cointegra√ß√£o: {str(e)}")
            coint_pvalue = np.nan
        
        # Res√≠duos para half-life com valida√ß√µes detalhadas
        try:
            if hasattr(model, 'resid') and len(model.resid) > 2:
                resids = model.resid
                
                # Verificar outliers nos res√≠duos
                z_scores = np.abs(stats.zscore(resids, nan_policy='omit'))
                if np.any(z_scores > 10):  # Outliers extremos
                    st.info("‚ÑπÔ∏è Detectados outliers extremos nos res√≠duos - considere filtrar os dados")
                
                # Calcular lag de res√≠duos com tratamento extra para arrays vazios
                lag_resids = pd.Series(resids).shift(1).dropna()
                
                # S√≥ prosseguir se tivermos dados suficientes
                if len(lag_resids) >= 2:
                    # Obter res√≠duos no mesmo √≠ndice dos lags
                    current_resids = pd.Series(resids).iloc[1:len(lag_resids)+1]
                    
                    # Verificar alinhamento de √≠ndices
                    if len(current_resids) != len(lag_resids):
                        # Garantir alinhamento
                        common_index = lag_resids.index.intersection(current_resids.index)
                        if len(common_index) < 2:
                            st.warning("‚ö†Ô∏è Dados insuficientes para c√°lculo de half-life ap√≥s alinhamento")
                            half_life = np.nan
                        else:
                            lag_resids = lag_resids[common_index]
                            current_resids = current_resids[common_index]
                    
                    # Calcular delta e prosseguir com c√°lculo de half-life
                    if len(lag_resids) >= 2 and len(current_resids) >= 2:
                        delta_resids = current_resids - lag_resids
                        
                        # Verificar se temos dados v√°lidos
                        if not delta_resids.isna().all() and not lag_resids.isna().all():
                            # Remover NaNs que possam ter surgido na subtra√ß√£o
                            mask = ~np.isnan(delta_resids) & ~np.isnan(lag_resids)
                            delta_resids_clean = delta_resids[mask]
                            lag_resids_clean = lag_resids[mask]
                            
                            if len(delta_resids_clean) >= 2:
                                # Regress√£o para half-life com valida√ß√µes
                                x_hl = sm.add_constant(lag_resids_clean)
                                try:
                                    model_hl = sm.OLS(delta_resids_clean, x_hl).fit()
                                    
                                    # Validar coeficiente antes de calcular half-life
                                    if model_hl.params[1] < 0 and np.isfinite(model_hl.params[1]):
                                        half_life = -np.log(2) / model_hl.params[1]
                                        
                                        # Verificar se half-life √© razo√°vel
                                        if not np.isfinite(half_life) or half_life <= 0 or half_life > 365:
                                            st.info(f"‚ÑπÔ∏è Half-life calculado ({half_life:.1f} dias) fora de intervalo razo√°vel")
                                            if half_life > 365:
                                                st.info("‚ÑπÔ∏è Half-life muito longo indica poss√≠vel n√£o-revers√£o √† m√©dia")
                                    else:
                                        st.info("‚ÑπÔ∏è Coeficiente de revers√£o √† m√©dia positivo - par n√£o apresenta converg√™ncia")
                                        half_life = np.nan
                                except Exception as e:
                                    st.warning(f"‚ö†Ô∏è Erro no modelo OLS para half-life: {str(e)}")
                                    half_life = np.nan
                            else:
                                st.warning("‚ö†Ô∏è Dados insuficientes para c√°lculo de half-life ap√≥s remo√ß√£o de NaNs")
                                half_life = np.nan
                        else:
                            st.warning("‚ö†Ô∏è Todos os valores s√£o NaN ap√≥s c√°lculo de delta")
                            half_life = np.nan
                    else:
                        st.warning("‚ö†Ô∏è Dados insuficientes para c√°lculo de delta res√≠duos")
                        half_life = np.nan
                else:
                    st.warning("‚ö†Ô∏è Dados insuficientes ap√≥s c√°lculo de lag")
                    half_life = np.nan
            else:
                st.warning("‚ö†Ô∏è Res√≠duos insuficientes para c√°lculo de half-life")
                half_life = np.nan
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Erro no c√°lculo do half-life: {str(e)}")
            half_life = np.nan
            
        # Teste ADF para estacionariedade com valida√ß√µes
        try:
            if hasattr(model, 'resid') and len(model.resid) >= 7:  # ADF precisa de um m√≠nimo de observa√ß√µes
                resids_for_adf = model.resid.copy()
                
                # Verificar valores n√£o finitos
                if np.any(~np.isfinite(resids_for_adf)):
                    st.warning("‚ö†Ô∏è Res√≠duos cont√™m valores n√£o finitos para teste ADF")
                    # Substituir valores n√£o finitos por NaN
                    resids_for_adf[~np.isfinite(resids_for_adf)] = np.nan
                
                # Remover NaNs
                resids_for_adf_clean = pd.Series(resids_for_adf).dropna()
                
                if len(resids_for_adf_clean) >= 7:
                    adf_result = sm.tsa.stattools.adfuller(resids_for_adf_clean)
                    adf_pvalue = adf_result[1]
                    
                    # Validar resultado ADF
                    if not np.isfinite(adf_pvalue):
                        st.warning("‚ö†Ô∏è Resultado do teste ADF √© um valor n√£o finito")
                        adf_pvalue = np.nan
                else:
                    st.warning("‚ö†Ô∏è Dados insuficientes para teste ADF ap√≥s remo√ß√£o de NaNs")
                    adf_pvalue = np.nan
            else:
                st.warning("‚ö†Ô∏è Res√≠duos insuficientes para teste ADF")
                adf_pvalue = np.nan
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Erro no teste ADF: {str(e)}")
            adf_pvalue = np.nan
    except Exception as e:        st.error(f"‚ùå Erro nos testes estat√≠sticos: {str(e)}")
        # As vari√°veis j√° foram inicializadas com np.nan no in√≠cio da fun√ß√£o
    
    col1, col2, col3 = st.columns(3)
    
    # Exibir m√©tricas com tratamento para NaN e valida√ß√µes adicionais
    with col1:
        if not np.isnan(coint_pvalue):
            color = "normal" if coint_pvalue >= 0.05 else "good"
            st.metric(
                "Teste de Cointegra√ß√£o (p-value)",
                f"{coint_pvalue:.4f}",
                "Cointegrado" if coint_pvalue < 0.05 else "N√£o cointegrado",
                delta_color=color
            )
        else:
            st.metric(
                "Teste de Cointegra√ß√£o (p-value)",
                "N/A"
            )
            st.info("‚ÑπÔ∏è N√£o foi poss√≠vel realizar teste de cointegra√ß√£o")
    
    with col2:
        if not np.isnan(half_life):
            if half_life > 0 and half_life < 365:  # Valor razo√°vel para half-life
                color = "good" if 2 <= half_life <= 30 else "normal"  # Half-life ideal entre 2-30 dias
                st.metric(
                    "Half-Life",
                    f"{half_life:.1f} dias",
                    delta_color=color
                )
                if half_life < 2:
                    st.info("‚ÑπÔ∏è Half-life muito curto - converg√™ncia muito r√°pida")
                elif half_life > 30:
                    st.info("‚ÑπÔ∏è Half-life longo - converg√™ncia lenta")
            else:
                st.metric(
                    "Half-Life",
                    f"{half_life:.1f} dias" if half_life > 0 else "Inv√°lido"
                )
                st.warning("‚ö†Ô∏è Half-life fora de intervalo razo√°vel")
        else:
            st.metric(
                "Half-Life",
                "N/A"
            )
            st.info("‚ÑπÔ∏è N√£o foi poss√≠vel calcular half-life")
    
    with col3:
        if not np.isnan(adf_pvalue):
            color = "normal" if adf_pvalue >= 0.05 else "good"
            st.metric(
                "ADF Test (p-value)",
                f"{adf_pvalue:.4f}",
                "Estacion√°rio" if adf_pvalue < 0.05 else "N√£o estacion√°rio",
                delta_color=color
            )
        else:
            st.metric(
                "ADF Test (p-value)",
                "N/A"
            )
            st.info("‚ÑπÔ∏è N√£o foi poss√≠vel realizar teste ADF")
    # Recomenda√ß√µes
    st.markdown("### üí° Recomenda√ß√µes")
    
    # Criar um indicador de qualidade geral dos testes
    tests_quality = 0
    tests_count = 0
    reasons = []
    
    # Verificar cointegra√ß√£o
    if not np.isnan(coint_pvalue):
        tests_count += 1
        if coint_pvalue < 0.05:
            tests_quality += 1
            reasons.append("‚úÖ Cointegra√ß√£o confirmada")
        else:
            reasons.append("‚ö†Ô∏è Cointegra√ß√£o n√£o confirmada")
    else:
        reasons.append("‚ö†Ô∏è Teste de cointegra√ß√£o inconclusivo")
    
    # Verificar half-life
    if not np.isnan(half_life):
        tests_count += 1
        if 2 <= half_life <= 30:
            tests_quality += 1
            reasons.append(f"‚úÖ Half-life adequado ({half_life:.1f} dias)")
        elif half_life > 0 and half_life < 100:
            tests_quality += 0.5
            if half_life < 2:
                reasons.append(f"‚ÑπÔ∏è Half-life muito curto ({half_life:.1f} dias)")
            else:
                reasons.append(f"‚ÑπÔ∏è Half-life longo ({half_life:.1f} dias)")
        else:
            reasons.append("‚ö†Ô∏è Half-life fora de intervalo aceit√°vel")
    else:
        reasons.append("‚ö†Ô∏è C√°lculo de half-life inconclusivo")
    
    # Verificar ADF
    if not np.isnan(adf_pvalue):
        tests_count += 1
        if adf_pvalue < 0.05:
            tests_quality += 1
            reasons.append("‚úÖ Res√≠duos estacion√°rios (ADF)")
        else:
            reasons.append("‚ö†Ô∏è Res√≠duos n√£o estacion√°rios (ADF)")
    else:
        reasons.append("‚ö†Ô∏è Teste ADF inconclusivo")
    
    # Verificar correla√ß√£o
    try:
        if not np.isnan(corr):
            tests_count += 1
            if abs(corr) > 0.6:
                tests_quality += 1
                reasons.append(f"‚úÖ Boa correla√ß√£o ({corr:.3f})")
            elif abs(corr) > 0.3:
                tests_quality += 0.5
                reasons.append(f"‚ÑπÔ∏è Correla√ß√£o moderada ({corr:.3f})")
            else:
                reasons.append(f"‚ö†Ô∏è Baixa correla√ß√£o ({corr:.3f})")
    except NameError:
        # corr pode n√£o estar definido se houve erro no c√°lculo
        pass
    
    # Calcular qualidade geral dos testes
    quality_score = tests_quality / max(tests_count, 1) if tests_count > 0 else 0
    
    # Recomenda√ß√µes baseadas na qualidade dos testes e resultados espec√≠ficos
    if tests_count < 3:
        st.warning("""
        ‚ö†Ô∏è **An√°lise inconclusiva**
        
        N√£o foi poss√≠vel realizar todos os testes estat√≠sticos necess√°rios devido a:
        - Dados insuficientes 
        - Valores ausentes ou inv√°lidos
        - Problemas nos c√°lculos estat√≠sticos
        
        **Sugest√µes:**
        - Utilize um per√≠odo maior de dados hist√≥ricos
        - Verifique a qualidade dos dados (valores ausentes, zeros, outliers)
        - Experimente outros pares de ativos com maior liquidez
        - Considere aplicar filtros ou transforma√ß√µes nos dados
        """)
    elif quality_score >= 0.75:
        # Lista os motivos da recomenda√ß√£o
        reasons_text = "\n".join([f"- {reason}" for reason in reasons if reason.startswith("‚úÖ")])
        
        st.success(f"""
        ‚úÖ **Par adequado para trading estat√≠stico**
        
        {reasons_text}
        
        **Pr√≥ximos passos:**
        - Implemente uma estrat√©gia de pair trading com este par
        - Defina os thresholds de entrada e sa√≠da baseados na an√°lise estat√≠stica
        - Estabele√ßa um stop-loss adequado considerando a volatilidade do par
        - Monitore a estabilidade da rela√ß√£o estat√≠stica ao longo do tempo
        """)
    elif quality_score >= 0.5:
        # Lista os pontos positivos e quest√µes a verificar
        positive_points = [reason for reason in reasons if reason.startswith("‚úÖ")]
        check_points = [reason for reason in reasons if reason.startswith("‚ÑπÔ∏è") or reason.startswith("‚ö†Ô∏è")]
        
        positive_text = "\n".join([f"- {point}" for point in positive_points])
        check_text = "\n".join([f"- {point}" for point in check_points])
        
        st.info(f"""
        ‚ÑπÔ∏è **Par potencialmente adequado - requer an√°lise adicional**
        
        **Pontos positivos:**
        {positive_text}
        
        **Pontos a verificar:**
        {check_text}
        
        **Recomenda√ß√µes:**
        - Realize backtests para validar a rela√ß√£o estat√≠stica
        - Considere per√≠odos de tempo distintos para verificar a estabilidade
        - Ajuste os par√¢metros de opera√ß√£o levando em conta as limita√ß√µes identificadas
        """)
    else:
        # Lista os problemas principais
        warnings_text = "\n".join([f"- {reason}" for reason in reasons if reason.startswith("‚ö†Ô∏è")])
        
        st.warning(f"""
        ‚ö†Ô∏è **Par n√£o recomendado para pair trading estat√≠stico**
        
        **Problemas identificados:**
        {warnings_text}
        
        **Alternativas:**
        - Analise outros pares com maior probabilidade de cointegra√ß√£o
        - Experimente diferentes per√≠odos de dados
        - Considere outros m√©todos de an√°lise estat√≠stica
        - Verifique se transforma√ß√µes (log, diferen√ßas) melhoram a rela√ß√£o
        """)


def documentation_tab():
    """
    Tab 5: Documenta√ß√£o
    
    Fornece documenta√ß√£o t√©cnica sobre as an√°lises estat√≠sticas
    implementadas no m√≥dulo, incluindo refer√™ncias acad√™micas
    e descri√ß√£o dos modelos utilizados.
    """
    st.subheader("üìö Documenta√ß√£o T√©cnica")
    
    st.markdown("""
    ### üìñ An√°lise Estat√≠stica Avan√ßada
    
    Esta se√ß√£o implementa diversos modelos estat√≠sticos para an√°lise
    de s√©ries temporais financeiras. Abaixo est√£o as descri√ß√µes dos
    principais modelos e metodologias utilizados.
    """)
    
    with st.expander("üéØ An√°lise de Eventos Extremos"):
        st.write("""
        #### üìâ Eventos Extremos
        
        **Metodologia**:
        - Estudo da probabilidade de eventos raros (large deviations)
        - An√°lise emp√≠rica de quedas extremas
        - Compara√ß√£o com distribui√ß√£o t-Student
        
        **Aplica√ß√£o**:
        - Quantifica√ß√£o de risco de cauda (tail risk)
        - Estima√ß√£o de probabilidades de drawdowns extremos
        - Simula√ß√£o de cen√°rios de estresse
        
        **F√≥rmulas-chave**:
        - Probabilidade emp√≠rica: `p = num_eventos_extremos / total_observa√ß√µes`
        - Estat√≠sticas de ordem: an√°lise de quantis emp√≠ricos
        """)
    
    with st.expander("üìà Compara√ß√£o de Distribui√ß√µes"):
        st.write("""
        #### üìä Compara√ß√£o Estat√≠stica
        
        **Testes Implementados**:
        - Kolmogorov-Smirnov: testa se duas amostras v√™m da mesma distribui√ß√£o
        - Mann-Whitney U: teste n√£o-param√©trico para diferen√ßas de medianas
        - Levene: teste para igualdade de vari√¢ncias
        - Anderson-Darling: teste de normalidade
        
        **Aplica√ß√£o**:
        - Identifica√ß√£o de ativos com comportamentos estat√≠sticos diferentes
        - An√°lise de mudan√ßas de regime em s√©ries temporais
        - Valida√ß√£o de hip√≥teses sobre distribui√ß√µes de retornos
        """)
    
    with st.expander("üî¨ Modelos de Risco"):
        st.write("""
        #### üìâ Value at Risk (VaR)
        
        **Metodologias**:
        - VaR Param√©trico: assumindo distribui√ß√£o Normal
        - VaR N√£o-param√©trico: baseado em quantis emp√≠ricos
        - VaR com t-Student: para melhor modelagem de caudas pesadas
        
        **CVaR (Expected Shortfall)**:
        - M√©dia das perdas al√©m do VaR
        - M√©trica coerente de risco
        - Mais sens√≠vel a eventos extremos que o VaR
        
        **Aplica√ß√£o**:
        - Gest√£o de risco de mercado
        - Aloca√ß√£o de capital baseada em risco
        - Stress testing de portfolios
        """)
    
    with st.expander("üîÑ Pair Trading"):
        st.write("""
        #### üìä Pair Trading Estat√≠stico
        
        **Metodologia**:
        - Testes de cointegra√ß√£o (Engle-Granger)
        - C√°lculo de half-life para m√©dia-revers√£o
        - Modelagem de spread estat√≠stico
        
        **M√©tricas-chave**:
        - p-value do teste de cointegra√ß√£o
        - Half-life de revers√£o √† m√©dia
        - Correla√ß√£o entre retornos
        
        **Aplica√ß√£o**:
        - Estrat√©gias de arbitragem estat√≠stica
        - Trading market-neutral
        - Hedge de exposi√ß√µes direcionais
        """)
    
    st.markdown("### üìã Refer√™ncias Bibliogr√°ficas")
    
    st.write("""
    1. Alexander, C. (2008). *Market Risk Analysis*. Wiley.
    2. Tsay, R.S. (2010). *Analysis of Financial Time Series*. Wiley.
    3. McNeil, A.J., Frey, R., & Embrechts, P. (2015). *Quantitative Risk Management*. Princeton University Press.
    4. Vidyamurthy, G. (2004). *Pairs Trading: Quantitative Methods and Analysis*. Wiley.
    5. Rodrigues, C.A. (2023). *Market-Neutral Portfolios: A Solution Based on Automated Strategies*. GLOBAL JOURNAL OF RESEARCHES IN ENGINEERING, v. 23, p. 1-10.
    """)
    
    st.markdown("### ‚ö†Ô∏è Notas e Limita√ß√µes")
    
    st.info("""
    **Limita√ß√µes dos Modelos**:
    
    - Modelos estat√≠sticos baseiam-se em dados hist√≥ricos, que podem n√£o representar condi√ß√µes futuras
    - Distribui√ß√µes de retornos financeiros frequentemente exibem caudas mais pesadas que as distribui√ß√µes te√≥ricas
    - Correla√ß√µes e outras rela√ß√µes estat√≠sticas podem mudar drasticamente em per√≠odos de estresse de mercado
    
    Recomenda-se complementar estas an√°lises estat√≠sticas com an√°lise fundamentalista e conhecimento do contexto macroecon√¥mico.
    """)
    
def _display_asset_extreme_analysis(stat_analyzer, df, asset_symbol=PETR4_SYMBOL, threshold=0.10):
    """
    Exibe an√°lise de eventos extremos para um ativo espec√≠fico.
    Esta fun√ß√£o tenta usar asset_extreme_analysis se existir, ou petrobras_extreme_analysis como fallback.
    Se nenhum m√©todo estiver dispon√≠vel, implementa uma an√°lise b√°sica.
    
    Args:
        stat_analyzer: Inst√¢ncia de StatisticalAnalysis 
        df: DataFrame de pre√ßos
        asset_symbol: S√≠mbolo do ativo a analisar (padr√£o: PETR4_SYMBOL)
        threshold: Threshold de queda para considerar extremo (padr√£o: 10%)
    """
    try:
        # Verificar se existe o m√©todo asset_extreme_analysis, caso contr√°rio usar petrobras_extreme_analysis
        if hasattr(stat_analyzer, 'asset_extreme_analysis'):
            extreme_analysis = stat_analyzer.asset_extreme_analysis(asset_symbol=asset_symbol, threshold=threshold)
        elif asset_symbol == PETR4_SYMBOL and hasattr(stat_analyzer, 'petrobras_extreme_analysis'):
            extreme_analysis = stat_analyzer.petrobras_extreme_analysis(threshold=threshold)
        else:
            # Criar an√°lise simplificada
            try:
                asset_returns = df[asset_symbol].pct_change().dropna()
                if len(asset_returns) == 0:
                    raise ValueError("Dados insuficientes para an√°lise")
                    
                extreme_falls = asset_returns[asset_returns <= -threshold]
                extreme_analysis = {
                    'asset_symbol': asset_symbol,
                    'total_days': len(asset_returns),
                    'extreme_falls_count': len(extreme_falls),
                    'probability': len(extreme_falls) / len(asset_returns) if len(asset_returns) > 0 else 0,
                    'daily_statistics': {
                        'mean': asset_returns.mean(),
                        'std': asset_returns.std(),
                        'skewness': skew(asset_returns) if len(asset_returns) > 3 else 0,
                        'kurtosis': kurtosis(asset_returns, fisher=True) if len(asset_returns) > 4 else 0,
                    }
                }
            except Exception as e:
                st.error(f"Erro ao calcular estat√≠sticas: {str(e)}")
                st.info("Implementando an√°lise m√≠nima de fallback.")
                
                # Vers√£o de emerg√™ncia com dados m√≠nimos
                extreme_analysis = {
                    'asset_symbol': asset_symbol,
                    'total_days': df.shape[0] if df is not None else 0,
                    'extreme_falls_count': 0,
                    'probability': 0,
                    'daily_statistics': {
                        'mean': 0,
                        'std': 0,
                        'skewness': 0,
                        'kurtosis': 0,
                    }
                }
            
        # Exibir resultados
        st.subheader(f"üìâ An√°lise de Eventos Extremos - {asset_symbol}")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            prob_empirical = extreme_analysis.get('probability', 0)
            st.metric("Prob. Emp√≠rica", f"{prob_empirical:.2%}")
        with col2:
            total_days = extreme_analysis.get('total_days', 0)
            extreme_count = extreme_analysis.get('extreme_falls_count', 0)
            st.metric("Eventos Extremos", f"{extreme_count}/{total_days}")
        with col3:
            daily_stats = extreme_analysis.get('daily_statistics', {})
            daily_vol = daily_stats.get('std', 0)
            annual_vol = daily_vol * np.sqrt(252)
            st.metric("Volatilidade Anual", f"{annual_vol:.1%}")
        with col4:
            skewness = daily_stats.get('skewness', 0)
            st.metric("Assimetria", f"{skewness:.2f}")
        
        # Exibir interpreta√ß√£o
        st.markdown("#### Interpreta√ß√£o dos Resultados")
        if prob_empirical > 0.05:  # 5%
            st.warning(f"""
            ‚ö†Ô∏è **Alto Risco**: Probabilidade de {prob_empirical:.1%} para quedas superiores a {threshold:.0%} 
            indica volatilidade elevada. Considere estrat√©gias de hedge.
            """)
        elif prob_empirical > 0.02:  # 2%
            st.info(f"""
            üí° **Risco Moderado**: Probabilidade de {prob_empirical:.1%} √© significativa. 
            Monitore indicadores macro e setoriais.
            """)
        else:
            st.success(f"""
            ‚úÖ **Risco Baixo**: Probabilidade de {prob_empirical:.1%} √© relativamente baixa 
            para quedas extremas no horizonte analisado.
            """)
        
    except Exception as e:
        st.error(f"Erro na an√°lise de extremos: {str(e)}")
        st.info("Falha ao executar an√°lise detalhada.")
